\begin{section}[]{\uppercase{Conclusion and Recommendation}}
 \addtocontents{toc}{\uppercase{Conclusion and Recommendation}}

 \subsection{Conclusion}
The main objective of the project are to detect deepfakes with the help of Dual Input Convolutional Neural Network (DICNN) and to evaluate the model. The research has been conducted to detect deepfakes using Deep Learning in various fields, especially in detection and recognition. 
The research will shed light on the use of and help in day-to-day life. 
The use of XAI in deepfake image detection is novel and is exclusively present in this research paper. The proposed system provides 99.17\% accuracy in detecting
deepfake images from real images. The results indicate that the proposed method is very robust at
detecting deepfake images and is also reliable and trustworthy because of the verification and integration
from XAI.
The SHAP \& LIME explainable AI are also used in this
research to describe which component of the image from the dataset caused the model to create specific
classifications, ensuring the modelâ€™s validity and reliability.
If this system was available in public, it would save hassle of dealing with fake content and fake information.
Eventhough, XAI is limited to images in present context, in near future, we can expect it to be used in videos and other forms of media.
Moreover, the research demonstrates the value of combining deep learning with explainable AI to ensure the transparency and trustworthiness of AI systems.



\subsection{Recommendation}
The trust in the developed model and its predictions are based on how well the model is trained and how well the model is explained. 
Further research can be carried out to improve the model and to make it more efficient and reliable. The findings show that the DICNN-XAI model is very efficient in detecting deepfake images from real images with high accuracy. This enhances the trust in DL systems enabling better understanding of system behavior.
In addition to SHAP used in base research paper, LIME was added to the research to provide more explanation to the model with 10x times the dataset. The results were compared and the model was evaluated. This study can be extended to videos and other forms of media to detect deepfakes. It can be used for other XAI algorithms like GradCAM, that can improve auguring problems.
Also more diverse data can be used to train the model to make it more robust and reliable. More heterogeneous data can ensure that the model developed is efficient. This current model can be extended to detect deepfakes in videos, which pose a more complex challenge due to the temporal dynamics involved.
 
\end{section}

\pagebreak

