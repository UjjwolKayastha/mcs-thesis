\pagestyle{plain}
\vspace*{52pt}
\begin{center}
    \large{\textbf{Abstract}}\\[31pt]
\end{center}

Deepfakes represent a significant challenge in today's digital landscape, creating hyper-realistic fake images and videos using advanced AI techniques like Generative Adversarial Networks (GANs). This research aims to develop a robust model for detecting DeepFake images utilizing a Dual Input Convolutional Neural Network (DICNN) combined with Explainable AI (XAI) techniques. 
By employing LIME (Local Interpretable Model-agnostic Explanations) and opting for better optimizer RMSProp (Root Mean Square Propagation), this study enhances the interpretability and reliability of the detection process. 
The DICNN model achieved an impressive accuracy rate, demonstrating its efficacy in identifying deepfakes. 
This research contributes to the ongoing efforts to combat digital misinformation and underscores the importance of explainable AI in building trust and transparency in machine learning models.
In literature review, the research highlights the accuracy of DICNN with other state-of-the-art models and the significance of combining deep learning with explainable AI to ensure the reliability of AI systems.
This study also highlights the differences in accuracy between two optimizers, RMSProp and Adam. 


\begin{flushleft}
    \textbf{Keywords:} Deepfakes, Convolutional Neural Networks, Explainable AI, SHAP, LIME, Deep Learning, Face Images, Face Detection
\end{flushleft}

\addtocontents{toc}{Abstract\hfill \thepage\par}